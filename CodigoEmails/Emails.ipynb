{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Emails.ipynb","provenance":[{"file_id":"1tblEGBofrDbruIqDRbL3vp79BnmhO51I","timestamp":1648943617800},{"file_id":"https://github.com/lpdiego/TP_Proyecto_Profesional_I_Grupo_11/blob/main/main.ipynb","timestamp":1648842352073}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introducción\n","\n","En esta notebook se llevarán a cabo los pasos para la implementación de un modelo que pueda detectar si un mensaje es spam o no.\n","Esta dividido por titulos con las acciones a seguir para la resolución del problema."],"metadata":{"id":"zfmITfElCq9-"}},{"cell_type":"markdown","source":["# Imports\n","\n","* Pandas nos ayudara para la obtencion de los datos en fuentes externas.\n","* De sklearn vamos a usar:\n","  1. train_test_split para entrenar y verificar un modelo.\n","  2. metrics para calcular la precisión del modelo.\n","  3. CountVectorizer para obtener una representación numérica de las palabras en los mensajes que se probaran en el algoritmo.\n","  4. MultinomialNB como algoritmo para el modelo (se utiliza Multinomial ya que se es util para la clasificación de texto).\n","* Drive de google para poder utilizar archivos de un Drive. \n","\n","\n","\n"],"metadata":{"id":"u0ecBTNfCIcQ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"ZvaGnV7HCF4c","executionInfo":{"status":"ok","timestamp":1649102323238,"user_tz":180,"elapsed":762,"user":{"displayName":"Luminam","userId":"06151251499338690167"}}},"outputs":[],"source":["import pandas as pd   #Para leer el csv\n","from sklearn.model_selection import train_test_split  #Separar en conjuntos de entrenamiento y validacion\n","from sklearn import metrics #Para calcular la tasa de exactitud del modelo\n","from sklearn.feature_extraction.text import CountVectorizer #Para generar las matrices de palabras\n","from sklearn.naive_bayes import MultinomialNB #El algoritmo de aprendizaje\n","from google.colab import drive  #Para montar el Drive\n","from wordcloud import WordCloud # Para mostrar graficos de las frecuencias de palabras\n","import matplotlib.pyplot as plt #Para ayudar a WordCloud\n","import pickle #Para exportar el modelo"]},{"cell_type":"markdown","source":["# Conexión con Drive\n","\n","Se establece una conexión con Drive. Para esto deberemos dar acceso a nuestro Drive a Google Colab."],"metadata":{"id":"d9C1J1CACZ2N"}},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"0sZXkZy1CcrW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Importación de datos desde Drive\n","\n","Se leen los datos de la carpeta del Drive. Para esto será necesario tener el acceso directo de la carpeta compartida \"Machine Learning TP\" en el directorio principal de Drive."],"metadata":{"id":"rC3vSQUACSPT"}},{"cell_type":"code","source":["mail_data = pd.read_csv('/content/drive/My Drive/Machine Learning TP - Llanos-Lopez/Datasets/Mails/mail_data.csv')"],"metadata":{"id":"dcSa6m2sCYby"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Separación de datos"],"metadata":{"id":"O1M1uZN_Cfln"}},{"cell_type":"markdown","source":["Como podemos ver, las categorias de la columna Category están representadas por los strings \"ham\" y \"spam\", por lo que es necesario convertirlas a un valor numérico para facilitar la resolución."],"metadata":{"id":"nAXVR720b6zq"}},{"cell_type":"code","source":["mail_data"],"metadata":{"id":"jnXkVcQzCt9v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En esta parte del código, entonces, modificamos a mail_data para que tenga valores numéricos en su categorización. Para los mensajes que son spam, se tendrá como representación al número 1 y para los que no son spam, el número 0. "],"metadata":{"id":"OePIgj4GcXqv"}},{"cell_type":"code","source":["mail_data = pd.get_dummies(data = mail_data, columns=['Category'], drop_first=True)\n","mail_data"],"metadata":{"id":"bdi3hZZ8bfW_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Aca se puede ver como hay 4825 mensajes que no son spam, y 747 que si lo son"],"metadata":{"id":"3q62jpVLARo3"}},{"cell_type":"code","source":["mail_data.groupby(\"Category_spam\").describe()"],"metadata":{"id":"ugYqQvlQhVZo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualización de datos\n","\n"],"metadata":{"id":"z_ByPDClLI6e"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"floating-presence"},"outputs":[],"source":["#WordCloud para ver palabras frecuentes en los emails ham\n","spam_words = ' '.join(list(mail_data[mail_data['Category_spam'] == 1]['Message']))\n","spam_wc = WordCloud(width = 512,height = 512).generate(spam_words)\n","plt.figure(figsize = (10, 8), facecolor = 'k')\n","plt.imshow(spam_wc)\n","plt.axis('off')\n","plt.tight_layout(pad = 0)\n","plt.show()"]},{"cell_type":"code","source":["#WordCloud para ver palabras frecuentes en los emails spam\n","spam_words = ' '.join(list(mail_data[mail_data['Category_spam'] == 0]['Message']))\n","spam_wc = WordCloud(width = 512,height = 512).generate(spam_words)\n","plt.figure(figsize = (10, 8), facecolor = 'k')\n","plt.imshow(spam_wc)\n","plt.axis('off')\n","plt.tight_layout(pad = 0)\n","plt.show()"],"metadata":{"id":"OyhqeXscAfxf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora que tenemos los datos como queremos, los separamos para entrenar al modelo. Para el testeo usaremos el %20 de los datos."],"metadata":{"id":"pBu_QCbTjzyu"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(mail_data.Message, mail_data.Category_spam, test_size = 0.2, shuffle=False)"],"metadata":{"id":"sHWpyRcQCmwP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["En esta parte transformamos los textos a arrays númericos para poder ser usados por el algoritmo MultinomialNB, por lo que ya tendríamos nuestros datos listos: X_train_count y y_train."],"metadata":{"id":"WE1CUAOdAr_O"}},{"cell_type":"code","source":["CV = CountVectorizer()\n","X_train_count = CV.fit_transform(X_train.values)"],"metadata":{"id":"qhVdZMCYlCQF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Creación y entrenamiento del modelo\n","\n","Ahora simplemente creamos el modelo con el algoritmo seleccionado y lo entrenamos con los datos seleccionados."],"metadata":{"id":"08M3zFh4CnGe"}},{"cell_type":"code","source":["model = MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\n","model.fit(X_train_count,y_train)"],"metadata":{"id":"BhY0bwhijxF5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluación del modelo\n","\n","En este paso transformamos los X_test y creamos una variable test que tendrá las predicciones hechas por el modelo."],"metadata":{"id":"PJMjFA_aCvz-"}},{"cell_type":"code","source":["X_test_count = CV.transform(X_test.values)\n","score = model.score(X_test_count, y_test)\n","print(score)"],"metadata":{"id":"AVnRrpy4tZNt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Aqui mostramos la precision del modelo. El valor mostrado puede cambiar al correr el programa multiples veces ya que en la parte de separación de datos se pueden elegir otros valores para testeo y entrenamiento (ya que es una elección aleatoria). En esta demostración, que varia de un rango desde el 0.0 a 1.0, un valor cercano a 1.0 significa una buena precisión."],"metadata":{"id":"jklxwOJNtaK8"}},{"cell_type":"markdown","source":["# Predicción"],"metadata":{"id":"ztK_0Yup2NgX"}},{"cell_type":"code","source":["def predecir(texto):\n","  email = [texto]\n","  texto_count = CV.transform(email)\n","  resultado = model.predict(texto_count)\n","  for i in resultado:\n","    if i == 0:\n","        print(\"ham\")\n","    elif i == 1:\n","        print(\"spam\")\n"],"metadata":{"id":"ThRzn5u8zM5D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predecir('Mila, age23, blonde, new in UK. I look sex with UK guys. if u like fun with me. Text MTALK to 69866.18 . 30pp/txt 1st 5free. Â£1.50 increments. Help08718728876')\n","predecir('Hi. Wk been ok - on hols now! Yes on for a bit of a run. Forgot that i have hairdressers appointment at four so need to get home n shower beforehand. Does that cause prob for u?')"],"metadata":{"id":"WM3gpBKm2rxX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exportación de modelo"],"metadata":{"id":"_S4KvvLiyhEU"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"manufactured-shepherd"},"outputs":[],"source":["#save the count vector file\n","with open('/content/drive/My Drive/Machine Learning TP - Llanos-Lopez/Modelos/Emails/count_vect.pkl', 'wb') as handle:\n","    pickle.dump(CV, handle, pickle.HIGHEST_PROTOCOL)"]},{"cell_type":"code","source":["#save the model file\n","with open('/content/drive/My Drive/Machine Learning TP - Llanos-Lopez/Modelos/Emails/emails_model.pkl', 'wb') as handle:\n","    pickle.dump(model, handle, pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"T2WhgRWpuU7Y"},"execution_count":null,"outputs":[]}]}